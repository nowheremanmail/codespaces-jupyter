{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M1.871 · Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Máster Universitario en Ciberseguridad y Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1\n",
    "\n",
    "--- \n",
    "\n",
    "Para resolver esta práctica, tenéis que poner las soluciones en el mismo\n",
    "*notebook*, en las celdas de código que están en blanco habilitadas para ello. Después de cada celda de código podéis poner una celda *markdown* en con la justificación de la respuesta dada en la solución. También \n",
    "podéis poner justificaciones en forma de comentario en las celdas de código. No es obligatorio, pero sí muy recomendable que justifiquéis las respuestas que dais, ya que eso facilita la corrección en caso de una respuesta incorrecta (pudiendo valorar el planteamiento).\n",
    "\n",
    "En muchos casos, cuando se pide implementar una función, se proporciona el nombre de la función y los parámetros, o algún tipo de esqueleto, indicando como ayuda el tipo de dichos parámetros y el tipo que retorna la función en forma de *type hint*. Es necesario que respetéis el nombre de la función y en la medida de los posibles los tipos. Sin embargo podéis implementar el código de la función con total libertad. Podéis\n",
    "definir otras funciones adicionales y no respetar del todo los *type hints* si así lo consideráis oportuno. \n",
    "\n",
    "Este notebook va acompañado de un cuestionario online con preguntas sobre los ejercicios. Este cuestionario debe ser contestado antes de la fecha de etrega de la práctica. **Se recomienda que afrontéis el cuestionario una vez finalizada la practica, habiendo realizado y entendido todos los ejercicios.** En muchos casos se proporcionan datos o posibles resultados con el objeto de ayudar a poder contestar el cuestionario aunque no se haya acabado o no se haya sabido implementar todos los ejercicios de este *notebook*.\n",
    "\n",
    "En algunas preguntas hay algunas indicaciones finales como *Hints*, son sugerencias sobre el uso de funciones que os pueden ser utiles. En cualquier caso se trata simplemente de eso, sugerencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Trabajaremos con datos que simulan el expediente academico de alumnos. Tenemos el fichero `data/students1.csv` que contiene 10000 registros con los siguientes atributos:\n",
    "- `name`: nombre del alumno/a,\n",
    "- `subject0`: nota de la asignatura 0 (valor real entre 0 y 10),\n",
    "- `subject1`: nota de la asignatura 1,\n",
    "- `subject2`: nota de la asignatura 2,\n",
    "- `subject3`: nota de la asignatura 3,\n",
    "\n",
    "No podemos publicar este fichero de microdatos, ya que se considera que la nota obtenida por el alumnado es privada. Es decir no podemos saber que nota ha obtenido una estudiante en concreto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicación de microdatos\n",
    "\n",
    "Queremos ahora poder publicar una versión protegida del fichero de microdatos `data/students1.csv`. Para poder trabajar con estos datos utilizaremos la libreira `pandas` de Python. De esta manera podemos leer el fichero en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10000 non-null  object \n",
      " 1   subject0  10000 non-null  float64\n",
      " 2   subject1  10000 non-null  float64\n",
      " 3   subject2  10000 non-null  float64\n",
      " 4   subject3  10000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subject0</th>\n",
       "      <th>subject1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>subject3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Susan Duffy</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erin Price</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvey Warren</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russell Sanchez</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bohrman</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Wilbert Meredith</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Thomas Gordon</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Kathryn Lakey</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Dewey Miesner</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Susan Tornatore</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  subject0  subject1  subject2  subject3\n",
       "0          Susan Duffy       8.5       6.1       1.0       8.8\n",
       "1           Erin Price       0.1       4.9       1.8       5.2\n",
       "2        Harvey Warren       2.5       7.0       4.1       9.7\n",
       "3      Russell Sanchez       6.5       6.4       6.1       9.0\n",
       "4         John Bohrman       0.8       9.7       2.3       5.3\n",
       "...                ...       ...       ...       ...       ...\n",
       "9995  Wilbert Meredith       0.3       1.8       6.1       9.8\n",
       "9996     Thomas Gordon       4.9       5.8      10.0       3.6\n",
       "9997     Kathryn Lakey       0.2      10.0       3.7       6.5\n",
       "9998     Dewey Miesner       8.8       8.5       1.5       5.2\n",
       "9999   Susan Tornatore       0.8       2.4       5.7       7.2\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"data/students1.csv\")\n",
    "df1.info()\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, ahora tenemos en la variable `df1` la tabla de microdatos en una estructura [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) de `pandas`. Notad que tamibén hemos importado la libreria `numpy`, ya que la utilizaremos más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 \n",
    "*[0.5p]*\n",
    "\n",
    "Para publicar estos datos primero tenemos que ver si se pueden publicar todos los atributos.\n",
    "\n",
    "En el caso de que haya algún atributo que no se pueda publicar, elimínalo del `DataFrame` `df1`.\n",
    "\n",
    "*Hint*:\n",
    "- [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   subject0  10000 non-null  float64\n",
      " 1   subject1  10000 non-null  float64\n",
      " 2   subject2  10000 non-null  float64\n",
      " 3   subject3  10000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "## Eliminaremos la columna name, que permitiría identificar totalmente el estudiante.\n",
    "\n",
    "df1 = df1.drop(columns=['name'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2 \n",
    "*[1.25p]*\n",
    "\n",
    "Para el resto de atributos vamos a utilizar **ruido aditivo no correlacionado**, tal como se describe en los materiales. \n",
    "\n",
    "Para ello vamos a utilizar una distribución normal $N(\\mu, \\sigma^2)$ con $\\mu = 0$, y como varianza tomaremos $\\sigma^2 = p \\sigma_o^2$\n",
    "donde $\\sigma_o^2$ es la varianza de la variable que queremos proteger.\n",
    "\n",
    "Desarrollad una función `noise_add_normal(df, p)` que recibe como parámetro `df`, el DataFrame a anonimizar y el parámetro `p`, y retorna una copia del DataFrame protegido, aplicando ruido a cada atributo. \n",
    "\n",
    "Finalmente, obtened una versión protegida en la variable `df1_noise_1` utilizando $p=0.1$.\n",
    "\n",
    "Algunas consideraciones:\n",
    "- cada atributo (variable o columna) tendrá una distribución de ruido independiente.\n",
    "- la función no puede modificar el DataFrame original, tiene que retornar un DataFrame nuevo.\n",
    "- tened cuidado a la hora de pasar la varianza a la distribución normal de la librería `numpy`, fijaros que espera recibir la desviación estándar (no la varianza).\n",
    "- el resultado después de aplicar ruido NO tiene que estar redondeado a un decimal (como sí lo estaban los valores originales), ni se tiene que aplicar ninguna corrección.\n",
    "\n",
    "\n",
    "*Hint*:\n",
    "- [`numpy.random.Generator.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal)\n",
    "- [Random sampling, quick start](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subject0  subject1   subject2   subject3\n",
      "0     8.891348  7.299611   1.742372   8.325803\n",
      "1    -0.465185  3.841311   2.823467   5.486780\n",
      "2     3.850125  6.320091   5.082273   9.339520\n",
      "3     6.467077  7.489220   6.488599   7.636956\n",
      "4     1.174545  8.459639   2.824799   5.027680\n",
      "...        ...       ...        ...        ...\n",
      "9995  0.301684  1.825976   7.453033  11.117158\n",
      "9996  5.935937  4.742500  10.078489   4.048299\n",
      "9997 -0.443788  9.758781   2.748919   5.651917\n",
      "9998  7.849397  8.291908   1.374914   5.296896\n",
      "9999  0.770313  2.192305   5.205549   8.711803\n",
      "\n",
      "[10000 rows x 4 columns]\n",
      "subject0\n",
      "      media antes=5.41787 despues=5.411758611745762\n",
      "  variancia antes=9.737967459845985 despues=10.703065847403598\n",
      "subject1\n",
      "      media antes=5.46277 despues=5.45445399371698\n",
      "  variancia antes=9.33161808890889 despues=10.254175618675086\n",
      "subject2\n",
      "      media antes=5.408580000000001 despues=5.420218267256868\n",
      "  variancia antes=9.470857469346933 despues=10.408759176097261\n",
      "subject3\n",
      "      media antes=5.3275500000000005 despues=5.328494661026388\n",
      "  variancia antes=9.768162813781379 despues=10.771408162761496\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def noise_add_normal(df: pd.DataFrame, p: float) -> pd.DataFrame:\n",
    "    ## Code goes here\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    result = pd.DataFrame(columns=df.columns)\n",
    "    for name, values in df.items():\n",
    "        N = values.size\n",
    "        variance = values.var()\n",
    "        sigma = math.sqrt(p*variance)\n",
    "        mu = 0\n",
    "        ## https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html\n",
    "        vector = rng.normal(mu, sigma, N)\n",
    "        result[name] = values + vector\n",
    "\n",
    "    return result\n",
    "\n",
    "## Code goes here\n",
    "df1_noise_1 = noise_add_normal(df1, 0.1)\n",
    "#df1_noise_1.info()\n",
    "print (df1_noise_1)\n",
    "\n",
    "for name, values in df1.items():\n",
    "    print (name)\n",
    "    print (\"      media antes=\" + str(values.mean()) + \" despues=\" + str(df1_noise_1[name].mean()))\n",
    "    print (\"  variancia antes=\" + str(values.var()) +  \" despues=\" + str(df1_noise_1[name].var()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como guía, los valores protegidos en `df1_noise_1` pueden ser algo parecido a lo que se muestra en la siguiente tabla.\n",
    "\n",
    "|  | subject0 |\tsubject1 |\tsubject2 |\tsubject3 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | 6.626006 |\t6.858254 |\t3.024407 |\t10.113438 |\n",
    "| 1 | -0.190741 |\t5.878539 |\t1.641941 |\t4.289627 |\n",
    "| 2 | 0.326832 |\t7.113423 |\t2.489244 |\t10.214147 |\n",
    "| 3 | 7.815629 |\t5.846698 |\t7.173413 |\t10.008515 |\n",
    "| 4 | 1.246823 |\t10.570642 |\t2.149917 |\t4.912380 |\n",
    "| 5 | ... | ... | ... | ... |\n",
    "| ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "*[1.25p]*\n",
    "\n",
    "En este ejercicio desarrollaremos dos medidas de **pérdida de información**.\n",
    "\n",
    "Para ello vamos a utilizar la siguiente notación:\n",
    "- $X$: conjunto de datos original. Lo podemos interpretar como una matriz de\n",
    "tamaño $n \\times d$ donde $n$ es el número de registros (filas) y $d$ el\n",
    "número de variables (columnas).\n",
    "- $X'$: conjunto de datos protegido, también $n \\times d$.\n",
    "- $R$: matriz de correlación de los datos originales $X$. Esta matriz es una matriz $d \\times d$ donde el elemento $(i,j)$ es la correlación entre la variable $V_i$ y $V_j$. Como medida de correlación tomaremos el coeficiente de correlación de Pearson.\n",
    "- $R'$: matriz de correlación de los datos protegidos $X'$.\n",
    "\n",
    "En cada caso mediremos la media del error absoluto MAE (*mean absolute error*). Es decir:\n",
    "- Sobre $X$, $X'$:\n",
    "  - *MAE*: $\\frac{1}{nd}\\sum_{j=1}^d \\sum_{i=1}^n \\mid x_{ij} - x'_{ij} \\mid$\n",
    "- Sobre $R$, $R'$:\n",
    "  - *MAE-corr*: $\\frac{1}{d^2}\\sum_{j=1}^d \\sum_{i=1}^n \\mid r_{ij} - r'_{ij} \\mid$\n",
    "\n",
    "Se pide la implementación de la función `information_loss(df_original, df_protected)` donde `df_original` es el DataFrame con los datos originales ($X$) y `df_protected` el DataFrame con los datos protegidos ($X'$). La función tiene que retornar dos valores, en este orden:\n",
    "- valor del MAE sobre $X$ y $X'$\n",
    "- valor del MAE sobre $R$ y $R'$\n",
    "\n",
    "Una vez implementada, aplicad la función para medir la pérdida de información al proteger los datos con $p=0.1$ (`df1_noise_1` del ejercicio anterior).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def information_loss(df_original: pd.DataFrame, df_protected: pd.DataFrame) -> Tuple[float, float]:\n",
    "    ## Code goes here\n",
    "\n",
    "## Code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "*[2p]*\n",
    "\n",
    "Queremos ahora producir una versión de los microdatos con el mayor nivel de ruido posible pero sin perder mucha información. Concretamente, queremos garantizar que el MAE (unicamente el MAE, no el MAE-corr) no supere el valor $3$.\n",
    "\n",
    "Es decir, ¿qué nivel de ruido (parámetro $p$) podemos aplicar de manera que obtengamos el mayor nivel de privacidad pero manteniendo la perdida de información según el MAE por debajo de $3.0$?\n",
    "\n",
    "Se pide que programéis el código para determinar dicho valor $p$. Para restringir la búsqueda, consideraremos que el parámetro $p$ puede tomar valores a partir de $0$ y siempre se expresará con un solo decimal. Es decir, podemos tener valores como $p=0.3$ o $p=1.2$ pero NO $p=0.31$ o $p=1.023$.\n",
    "\n",
    "Tenéis que mostrar al final el valor de $p$ que buscamos y el MAE obtenido con dicho valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "*[1.25p]*\n",
    "\n",
    "Con el valor $p$ obtenido en el ejercicio anterior, vamos a obtener un nuevo DataFrame protegido:\n",
    "```Python\n",
    "df_protected_final = noise_add_normal(df1, p)\n",
    "```\n",
    "(Si no has podido acabar el ejercicio anterior, utiliza el valor $p=1.8$, que no tiene por qué ser igual a la solución de dicho ejercicio)\n",
    "\n",
    "Este será el fichero de microdatos publicado. Para ver que diferencias tenemos respecto al original se pide comparar los siguientes valores entre el fichero de notas original (`df1`) y el protegido (`df_protected_final`):\n",
    "- media de cada asignatura por separado.\n",
    "- media de todas las asignaturas.\n",
    "- nota máxima y mínima de cada asignatura por separado\n",
    "- nota máxima y mínima de todas las asignaturas.\n",
    "\n",
    "Para ello, tenéis que implementar una función `compute_statistics` que reciba como parámetro un `DataFrame` con las notas y retorne un diccionario con los valores requeridos. Como ejemplo, si aplicamos la función a los datos originales, `df1`, debería retornar:\n",
    "```python\n",
    "{'avg_s0': 5.4178700000000015,\n",
    " 'avg_s1': 5.462769999999979,\n",
    " 'avg_s2': 5.408580000000002,\n",
    " 'avg_s3': 5.327550000000016,\n",
    " 'avg_total': 5.4041925,\n",
    " 'max_s0': 10.0,\n",
    " 'max_s1': 10.0,\n",
    " 'max_s2': 10.0,\n",
    " 'max_s3': 10.0,\n",
    " 'max_total': 10.0,\n",
    " 'min_s0': 0.0,\n",
    " 'min_s1': 0.0,\n",
    " 'min_s2': 0.0,\n",
    " 'min_s3': 0.0,\n",
    " 'min_total': 0.0}\n",
    "```\n",
    "De esta manera podemos comparar los valores sobre `df1` y `df_protected_final`\n",
    "```python\n",
    "stats = pd.DataFrame([compute_statistics(df1), compute_statistics(df_protected_final)])\n",
    "\n",
    "```\n",
    "En `stats` tenemos un `DataFrame` donde podemos ver los resultados.\n",
    "`\n",
    "En este ejercicio se pide:\n",
    "- implementar la función `compute_statistics` tal como se pide,\n",
    "- mostrar el resultado en el `DataFrame` stats como se indica anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def compute_statistics(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    ## Code goes here\n",
    "    \n",
    "## Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacidad diferencial\n",
    "\n",
    "Ahora vamos a ver el enfoque que propone la privacidad diferencial, y para ello implementaremos de forma simulada una base de datos como una clase de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La siguiente clase implementa una sencilla base de datos `MyDB`. La base de datos lee el fichero CSV que contiene los datos con las notas de los estudiantes.\n",
    "\n",
    "Como vemos, se trata de una base de datos muy sencilla y simplificada, que únicamente tiene sentido con fines docentes. La idea es que la clase `MyDB` simula una base de datos y sus métodos públicos son las consultas que pueden hacer los usuarios. Asumimos que un usuario no puede ver el contenido del objeto y simplemente puede acceder a `MyDB` mediante sus métodos.\n",
    "\n",
    "La clase `MyDB` se instancia a partir de un fichero CSV que se guarda como un `DataFrame` de `pandas`. Esta clase implementa 1 método para obtener información sobre las estudiantes de la base de datos:\n",
    "- `count_all_fail`: que retorna el número de estudiantes que han suspendido todas las asignaturas.\n",
    "\n",
    "Recordamos que asumimos que la única manera que tiene cualquier usuario para acceder a los datos es llamar a esta función `count_all_fail`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDB:\n",
    "    def __init__(self, filename: str) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "\n",
    "    def count_all_fail(self) -> int:\n",
    "        return self.df[\n",
    "            (self.df[\"subject0\"] < 5)\n",
    "            & (self.df[\"subject1\"] < 5)\n",
    "            & (self.df[\"subject2\"] < 5)\n",
    "            & (self.df[\"subject3\"] < 5)\n",
    "            ].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, a continuación vemos como se instanciaría `SimpleDB` con el fichero `data/students1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "\n",
    "print(f\"DB1 count_all_fail: {db1.count_all_fail()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "*[0.5p]*\n",
    "\n",
    "Vamos ahora a estudiar la privacidad que ofrece `MyDB` según la definición de privacidad diferencial. Con el objeto de poder hacer diversas pruebas tenemos dos ficheros CSV:\n",
    "- `data/students1.csv`: con 10000 registros\n",
    "- `data/students2.csv`: con 9999 registros\n",
    "\n",
    "Podemos ver que `students2.csv` es igual a `students1.csv` con la diferencia de que le falta un registro, el correspondiente a *Susan Duffy*. En principio podemos asumir que un posible atacante sabe que este es el registro que falta (el correspondiente a esta estudiante no está en DB2 y sí en DB1), pero no sabe sus datos: notas obtenidas en las asignaturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "db2 = MyDB(\"data/students2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observando el resultado de hacer la consulta `count_all_fail` a `db1` y `db2`. ¿Qué información podemos obtener? (Muestra el resultado de las consultas y añade la respuesta y su justificación como comentario).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "*[1.25p]*\n",
    "\n",
    "Vamos a implementar una nueva base de datos que implemente la versión segura del método `count_all_fail` utilizando el mecanismo de Laplace. Para ello crearemos una nueva clase de base de datos a la que llamaremos `MyPrivateDB`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementa, en la siguiente clase, el método `dp_count_all_fail` que retorne el número de alumnos y alumnas que han suspendido todas las asignaturas, pero esta vez la respuesta ha de estar protegida utilizando **el mecanismo de Laplace**.\n",
    "\n",
    "Para hacerlo necesitaremos:\n",
    "- Calcular o determinar la sensibilidad global del método.\n",
    "- Generar ruido con una distribución de Laplace basándonos en su sensibilidad global y el parámetro *epsilon*.\n",
    "- Retornar el valor con el ruido añadido.\n",
    "\n",
    "Como vemos, el parámetro *epsilon* se fija en el constructor de la clase. Importante: de momento asumimos que únicamente se realizará una consulta.\n",
    "\n",
    "*Hint*: \n",
    "- [random.Generator.laplace](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.laplace.html#numpy.random.Generator.laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyPrivateDB:\n",
    "    def __init__(self, filename: str, epsilon: float) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def dp_count_all_fail(self) -> int:\n",
    "        ## Code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "*[0.5p]*\n",
    "\n",
    "Podemos ver el resultado de hacer la consulta `dp_count_all_fail` con la nueva base de datos `MyPrivateDB` a los datos de `data/students1.csv` y `data/students2.csv`.\n",
    "\n",
    "¿Podemos ahora obtener la misma información que en el Ejercicio 6? Muestra el resultado para `epsilon=1`, responde y justifica en forma de comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "*[2p]*\n",
    "\n",
    "Hemos asumido al principio que el usuario o usuaria únicamente realizará una consulta (llamará a la función `dp_count_all_fail()` una vez).\n",
    "\n",
    "Si ahora asumimos que se puede hacer más de una consulta, y sin modificar la implementación de nuestro método `dp_count_all_fail`, un atacante ¿podría llegar a obtener la misma información que proporcionaba el método `count_all_fail` pero utilizando `dp_count_all_fail`?\n",
    "\n",
    "En este ejercicio se pide implementar el posible ataque que permita desanonimizar `dp_count_all_fail` (es decir, utilizando `MyPrivateDB`) y con la particularidad de que se puede repetir dicha consulta sobre una misma base de datos diversas veces. En este caso lo haremos para `epsilon=8`. Justifica el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code goes here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "name": "pra1-notebook.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
