{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M1.871 · Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Máster Universitario en Ciberseguridad y Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1\n",
    "\n",
    "--- \n",
    "\n",
    "Para resolver esta práctica, tenéis que poner las soluciones en el mismo\n",
    "*notebook*, en las celdas de código que están en blanco habilitadas para ello. Después de cada celda de código podéis poner una celda *markdown* en con la justificación de la respuesta dada en la solución. También \n",
    "podéis poner justificaciones en forma de comentario en las celdas de código. No es obligatorio, pero sí muy recomendable que justifiquéis las respuestas que dais, ya que eso facilita la corrección en caso de una respuesta incorrecta (pudiendo valorar el planteamiento).\n",
    "\n",
    "En muchos casos, cuando se pide implementar una función, se proporciona el nombre de la función y los parámetros, o algún tipo de esqueleto, indicando como ayuda el tipo de dichos parámetros y el tipo que retorna la función en forma de *type hint*. Es necesario que respetéis el nombre de la función y en la medida de los posibles los tipos. Sin embargo podéis implementar el código de la función con total libertad. Podéis\n",
    "definir otras funciones adicionales y no respetar del todo los *type hints* si así lo consideráis oportuno. \n",
    "\n",
    "Este notebook va acompañado de un cuestionario online con preguntas sobre los ejercicios. Este cuestionario debe ser contestado antes de la fecha de etrega de la práctica. **Se recomienda que afrontéis el cuestionario una vez finalizada la practica, habiendo realizado y entendido todos los ejercicios.** En muchos casos se proporcionan datos o posibles resultados con el objeto de ayudar a poder contestar el cuestionario aunque no se haya acabado o no se haya sabido implementar todos los ejercicios de este *notebook*.\n",
    "\n",
    "En algunas preguntas hay algunas indicaciones finales como *Hints*, son sugerencias sobre el uso de funciones que os pueden ser utiles. En cualquier caso se trata simplemente de eso, sugerencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Trabajaremos con datos que simulan el expediente academico de alumnos. Tenemos el fichero `data/students1.csv` que contiene 10000 registros con los siguientes atributos:\n",
    "- `name`: nombre del alumno/a,\n",
    "- `subject0`: nota de la asignatura 0 (valor real entre 0 y 10),\n",
    "- `subject1`: nota de la asignatura 1,\n",
    "- `subject2`: nota de la asignatura 2,\n",
    "- `subject3`: nota de la asignatura 3,\n",
    "\n",
    "No podemos publicar este fichero de microdatos, ya que se considera que la nota obtenida por el alumnado es privada. Es decir no podemos saber que nota ha obtenido una estudiante en concreto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicación de microdatos\n",
    "\n",
    "Queremos ahora poder publicar una versión protegida del fichero de microdatos `data/students1.csv`. Para poder trabajar con estos datos utilizaremos la libreira `pandas` de Python. De esta manera podemos leer el fichero en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10000 non-null  object \n",
      " 1   subject0  10000 non-null  float64\n",
      " 2   subject1  10000 non-null  float64\n",
      " 3   subject2  10000 non-null  float64\n",
      " 4   subject3  10000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subject0</th>\n",
       "      <th>subject1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>subject3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Susan Duffy</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erin Price</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvey Warren</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russell Sanchez</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bohrman</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Wilbert Meredith</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Thomas Gordon</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Kathryn Lakey</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Dewey Miesner</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Susan Tornatore</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  subject0  subject1  subject2  subject3\n",
       "0          Susan Duffy       8.5       6.1       1.0       8.8\n",
       "1           Erin Price       0.1       4.9       1.8       5.2\n",
       "2        Harvey Warren       2.5       7.0       4.1       9.7\n",
       "3      Russell Sanchez       6.5       6.4       6.1       9.0\n",
       "4         John Bohrman       0.8       9.7       2.3       5.3\n",
       "...                ...       ...       ...       ...       ...\n",
       "9995  Wilbert Meredith       0.3       1.8       6.1       9.8\n",
       "9996     Thomas Gordon       4.9       5.8      10.0       3.6\n",
       "9997     Kathryn Lakey       0.2      10.0       3.7       6.5\n",
       "9998     Dewey Miesner       8.8       8.5       1.5       5.2\n",
       "9999   Susan Tornatore       0.8       2.4       5.7       7.2\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"data/students1.csv\")\n",
    "df1.info()\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, ahora tenemos en la variable `df1` la tabla de microdatos en una estructura [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) de `pandas`. Notad que tamibén hemos importado la libreria `numpy`, ya que la utilizaremos más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 \n",
    "*[0.5p]*\n",
    "\n",
    "Para publicar estos datos primero tenemos que ver si se pueden publicar todos los atributos.\n",
    "\n",
    "En el caso de que haya algún atributo que no se pueda publicar, elimínalo del `DataFrame` `df1`.\n",
    "\n",
    "*Hint*:\n",
    "- [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   subject0  10000 non-null  float64\n",
      " 1   subject1  10000 non-null  float64\n",
      " 2   subject2  10000 non-null  float64\n",
      " 3   subject3  10000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "## Eliminaremos la columna name, que permitiría identificar totalmente el estudiante.\n",
    "\n",
    "df1 = df1.drop(columns=['name'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2 \n",
    "*[1.25p]*\n",
    "\n",
    "Para el resto de atributos vamos a utilizar **ruido aditivo no correlacionado**, tal como se describe en los materiales. \n",
    "\n",
    "Para ello vamos a utilizar una distribución normal $N(\\mu, \\sigma^2)$ con $\\mu = 0$, y como varianza tomaremos $\\sigma^2 = p \\sigma_o^2$\n",
    "donde $\\sigma_o^2$ es la varianza de la variable que queremos proteger.\n",
    "\n",
    "Desarrollad una función `noise_add_normal(df, p)` que recibe como parámetro `df`, el DataFrame a anonimizar y el parámetro `p`, y retorna una copia del DataFrame protegido, aplicando ruido a cada atributo. \n",
    "\n",
    "Finalmente, obtened una versión protegida en la variable `df1_noise_1` utilizando $p=0.1$.\n",
    "\n",
    "Algunas consideraciones:\n",
    "- cada atributo (variable o columna) tendrá una distribución de ruido independiente.\n",
    "- la función no puede modificar el DataFrame original, tiene que retornar un DataFrame nuevo.\n",
    "- tened cuidado a la hora de pasar la varianza a la distribución normal de la librería `numpy`, fijaros que espera recibir la desviación estándar (no la varianza).\n",
    "- el resultado después de aplicar ruido NO tiene que estar redondeado a un decimal (como sí lo estaban los valores originales), ni se tiene que aplicar ninguna corrección.\n",
    "\n",
    "\n",
    "*Hint*:\n",
    "- [`numpy.random.Generator.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal)\n",
    "- [Random sampling, quick start](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subject0   subject1  subject2   subject3\n",
      "0     9.715860   7.237924  0.315162   8.258443\n",
      "1    -0.001542   5.618070  3.548728   7.079863\n",
      "2     2.941535   5.132987  6.068056   9.330093\n",
      "3     6.298366   6.697849  6.857184   9.097682\n",
      "4     1.310652   9.452741  1.506636   5.108540\n",
      "...        ...        ...       ...        ...\n",
      "9995  0.351684   0.360472  8.834801  10.783407\n",
      "9996  5.754225   5.448386  9.245939   5.072592\n",
      "9997  2.938843  12.460461  3.231329   6.557660\n",
      "9998  6.562335   8.982930  1.174824   5.988478\n",
      "9999  2.063235   0.647393  4.831024   6.024327\n",
      "\n",
      "[10000 rows x 4 columns]\n",
      "subject0\n",
      "      media antes=5.41787 despues=5.4324218065011705\n",
      "  variancia antes=9.737967459845985 despues=10.608356907622232\n",
      "subject1\n",
      "      media antes=5.46277 despues=5.452997633687718\n",
      "  variancia antes=9.33161808890889 despues=10.239441719239597\n",
      "subject2\n",
      "      media antes=5.408580000000001 despues=5.4229257478259765\n",
      "  variancia antes=9.470857469346933 despues=10.39027995994526\n",
      "subject3\n",
      "      media antes=5.3275500000000005 despues=5.329039823100003\n",
      "  variancia antes=9.768162813781379 despues=10.793367465735658\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def noise_add_normal(df: pd.DataFrame, p: float) -> pd.DataFrame:\n",
    "    ## Code goes here\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    result = pd.DataFrame(columns=df.columns)\n",
    "    for name, values in df.items():\n",
    "        N = values.size\n",
    "        variance = values.var()\n",
    "        sigma = math.sqrt(p*variance)\n",
    "        mu = 0\n",
    "        ## https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html\n",
    "        vector = rng.normal(mu, sigma, N)\n",
    "        result[name] = values + vector\n",
    "\n",
    "    return result\n",
    "\n",
    "## Code goes here\n",
    "df1_noise_1 = noise_add_normal(df1, 0.1)\n",
    "#df1_noise_1.info()\n",
    "print (df1_noise_1)\n",
    "\n",
    "for name, values in df1.items():\n",
    "    print (name)\n",
    "    print (f\"      media antes={values.mean()} despues={df1_noise_1[name].mean()}\")\n",
    "    print (f\"  variancia antes={values.var()} despues={df1_noise_1[name].var()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como guía, los valores protegidos en `df1_noise_1` pueden ser algo parecido a lo que se muestra en la siguiente tabla.\n",
    "\n",
    "|  | subject0 |\tsubject1 |\tsubject2 |\tsubject3 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | 6.626006 |\t6.858254 |\t3.024407 |\t10.113438 |\n",
    "| 1 | -0.190741 |\t5.878539 |\t1.641941 |\t4.289627 |\n",
    "| 2 | 0.326832 |\t7.113423 |\t2.489244 |\t10.214147 |\n",
    "| 3 | 7.815629 |\t5.846698 |\t7.173413 |\t10.008515 |\n",
    "| 4 | 1.246823 |\t10.570642 |\t2.149917 |\t4.912380 |\n",
    "| 5 | ... | ... | ... | ... |\n",
    "| ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "*[1.25p]*\n",
    "\n",
    "En este ejercicio desarrollaremos dos medidas de **pérdida de información**.\n",
    "\n",
    "Para ello vamos a utilizar la siguiente notación:\n",
    "- $X$: conjunto de datos original. Lo podemos interpretar como una matriz de\n",
    "tamaño $n \\times d$ donde $n$ es el número de registros (filas) y $d$ el\n",
    "número de variables (columnas).\n",
    "- $X'$: conjunto de datos protegido, también $n \\times d$.\n",
    "- $R$: matriz de correlación de los datos originales $X$. Esta matriz es una matriz $d \\times d$ donde el elemento $(i,j)$ es la correlación entre la variable $V_i$ y $V_j$. Como medida de correlación tomaremos el coeficiente de correlación de Pearson.\n",
    "- $R'$: matriz de correlación de los datos protegidos $X'$.\n",
    "\n",
    "En cada caso mediremos la media del error absoluto MAE (*mean absolute error*). Es decir:\n",
    "- Sobre $X$, $X'$:\n",
    "  - *MAE*: $\\frac{1}{nd}\\sum_{j=1}^d \\sum_{i=1}^n \\mid x_{ij} - x'_{ij} \\mid$\n",
    "- Sobre $R$, $R'$:\n",
    "  - *MAE-corr*: $\\frac{1}{d^2}\\sum_{j=1}^d \\sum_{i=1}^n \\mid r_{ij} - r'_{ij} \\mid$\n",
    "\n",
    "Se pide la implementación de la función `information_loss(df_original, df_protected)` donde `df_original` es el DataFrame con los datos originales ($X$) y `df_protected` el DataFrame con los datos protegidos ($X'$). La función tiene que retornar dos valores, en este orden:\n",
    "- valor del MAE sobre $X$ y $X'$\n",
    "- valor del MAE sobre $R$ y $R'$\n",
    "\n",
    "Una vez implementada, aplicad la función para medir la pérdida de información al proteger los datos con $p=0.1$ (`df1_noise_1` del ejercicio anterior).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdida de información [0.19524913058322446, 0.000803730756544534]\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def MAE(df_original: pd.DataFrame, df_protected: pd.DataFrame) -> float:\n",
    "    d = df_original.columns.size\n",
    "    N = df_original.size\n",
    "\n",
    "    ## MAE sobre los datos\n",
    "    suma = 0.0\n",
    "    for name, values in df_original.items():\n",
    "        tmp = abs(values - df_protected[name])\n",
    "        suma = suma + sum(tmp)\n",
    "    #print (suma)\n",
    "    return suma  / (N * d)\n",
    "\n",
    "def MAE_matrix(original: np.array, protected: np.array) -> float:\n",
    "    d = len(original)\n",
    "    tmp = abs(original - protected)\n",
    "    #print (tmp)    \n",
    "    suma = sum(sum(tmp))\n",
    "    #print (suma)\n",
    "    return suma  / (d * d)\n",
    "\n",
    "def matriz_covarianza (df_original: pd.DataFrame) -> np.array:\n",
    "    ## calculamos la matriz de covarianza cov(Vi,Vj)\n",
    "    d = df_original.columns.size\n",
    "    N = df_original.size\n",
    "    covarianza = [[0 for _ in range(d)] for _ in range(d)]\n",
    "    for idx1, name1 in enumerate(df_original.columns):\n",
    "        values1 = df_original[name1]\n",
    "        media1 = values1.mean()\n",
    "        for idx2, name2 in enumerate(df_original.columns):\n",
    "            values2 = df_original[name2]\n",
    "            media2 = values2.mean()\n",
    "            if name1 != name2:\n",
    "                covij = sum((values1 - media1)*(values2 - media2)) / N\n",
    "                #print (name1 + \"-\" + name2 + \" \" + str(covij))\n",
    "                covarianza[idx1][idx2] = covij\n",
    "            else:\n",
    "                covarianza[idx1][idx2] = 0.0\n",
    "    #print (covarianza)\n",
    "    return np.array(covarianza)\n",
    "\n",
    "def matriz_correlacion (df_original: pd.DataFrame) -> np.array:\n",
    "    ## calculamos la matriz de covarianza cov(Vi,Vj) y la dividimos por la desviacion estandar\n",
    "    d = df_original.columns.size\n",
    "    N = df_original.size\n",
    "    covarianza = [[0 for _ in range(d)] for _ in range(d)]\n",
    "    for idx1, name1 in enumerate(df_original.columns):\n",
    "        values1 = df_original[name1]\n",
    "        stddev1 = math.sqrt(values1.var())\n",
    "        media1 = values1.mean()\n",
    "        for idx2, name2 in enumerate(df_original.columns):\n",
    "            values2 = df_original[name2]\n",
    "            stddev2 = math.sqrt(values2.var())\n",
    "            media2 = values2.mean()\n",
    "            if name1 != name2:\n",
    "                covij = sum((values1 - media1)*(values2 - media2)) / N\n",
    "                #print (name1 + \"-\" + name2 + \" \" + str(covij))\n",
    "                # coeficiente de correlación de Pearson\n",
    "                covarianza[idx1][idx2] = covij / (stddev1 * stddev2) \n",
    "            else:\n",
    "                covarianza[idx1][idx2] = 0.0\n",
    "    #print (covarianza)\n",
    "    return np.array(covarianza)\n",
    "\n",
    "def information_loss(df_original: pd.DataFrame, df_protected: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \n",
    "    ## calculamos el MAE (mean absolute error) entre la original y la modificada\n",
    "    mae = MAE(df_original, df_protected)\n",
    "\n",
    "    ## calculo de las matrices de correlación\n",
    "\n",
    "    ## calculamos la matriz de correlacion del original cov(Vi,Vj)/std*std\n",
    "    correlacion_original = matriz_correlacion (df_original)\n",
    "    ## calculamos la matriz de correlacion del modificado cov(Vi,Vj)/std*std\n",
    "    correlacion_protected = matriz_correlacion (df_protected)\n",
    "\n",
    "    ## calculamos el MAE (mean absolute error) entre las matirzes de correlacion\n",
    "    mae_corr = MAE_matrix(correlacion_original, correlacion_protected)\n",
    "\n",
    "    return [mae, mae_corr]\n",
    "\n",
    "## Code goes here\n",
    "print (f\"Perdida de información {information_loss(df1, df1_noise_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "*[2p]*\n",
    "\n",
    "Queremos ahora producir una versión de los microdatos con el mayor nivel de ruido posible pero sin perder mucha información. Concretamente, queremos garantizar que el MAE (unicamente el MAE, no el MAE-corr) no supere el valor $3$.\n",
    "\n",
    "Es decir, ¿qué nivel de ruido (parámetro $p$) podemos aplicar de manera que obtengamos el mayor nivel de privacidad pero manteniendo la perdida de información según el MAE por debajo de $3.0$?\n",
    "\n",
    "Se pide que programéis el código para determinar dicho valor $p$. Para restringir la búsqueda, consideraremos que el parámetro $p$ puede tomar valores a partir de $0$ y siempre se expresará con un solo decimal. Es decir, podemos tener valores como $p=0.3$ o $p=1.2$ pero NO $p=0.31$ o $p=1.023$.\n",
    "\n",
    "Tenéis que mostrar al final el valor de $p$ que buscamos y el MAE obtenido con dicho valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor p utilizado 23.400000000000063 con MAE 2.9736782689654744\n"
     ]
    }
   ],
   "source": [
    "## Code goes here\n",
    "p = 0.0\n",
    "found = False\n",
    "\n",
    "while not found:\n",
    "    #print (str(p))\n",
    "    df1_noise_2 = noise_add_normal(df1, p)\n",
    "    mae_pairs = information_loss(df1, df1_noise_2)\n",
    "    \n",
    "    if (mae_pairs[0] > 3.0):\n",
    "        found = True\n",
    "    else:\n",
    "        #print (mae_pairs)\n",
    "        df1_noise_2_found = df1_noise_2\n",
    "        mae_pairs_found = mae_pairs\n",
    "        p_found = p\n",
    "    p = p + 0.1\n",
    "\n",
    "if found:\n",
    "    print (f\"Valor p utilizado {p_found} con MAE {mae_pairs_found[0]}\")    \n",
    "else:\n",
    "    print (\"No he encontrado ningún valor\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "*[1.25p]*\n",
    "\n",
    "Con el valor $p$ obtenido en el ejercicio anterior, vamos a obtener un nuevo DataFrame protegido:\n",
    "```Python\n",
    "df_protected_final = noise_add_normal(df1, p)\n",
    "```\n",
    "(Si no has podido acabar el ejercicio anterior, utiliza el valor $p=1.8$, que no tiene por qué ser igual a la solución de dicho ejercicio)\n",
    "\n",
    "Este será el fichero de microdatos publicado. Para ver que diferencias tenemos respecto al original se pide comparar los siguientes valores entre el fichero de notas original (`df1`) y el protegido (`df_protected_final`):\n",
    "- media de cada asignatura por separado.\n",
    "- media de todas las asignaturas.\n",
    "- nota máxima y mínima de cada asignatura por separado\n",
    "- nota máxima y mínima de todas las asignaturas.\n",
    "\n",
    "Para ello, tenéis que implementar una función `compute_statistics` que reciba como parámetro un `DataFrame` con las notas y retorne un diccionario con los valores requeridos. Como ejemplo, si aplicamos la función a los datos originales, `df1`, debería retornar:\n",
    "```python\n",
    "{'avg_s0': 5.4178700000000015,\n",
    " 'avg_s1': 5.462769999999979,\n",
    " 'avg_s2': 5.408580000000002,\n",
    " 'avg_s3': 5.327550000000016,\n",
    " 'avg_total': 5.4041925,\n",
    " 'max_s0': 10.0,\n",
    " 'max_s1': 10.0,\n",
    " 'max_s2': 10.0,\n",
    " 'max_s3': 10.0,\n",
    " 'max_total': 10.0,\n",
    " 'min_s0': 0.0,\n",
    " 'min_s1': 0.0,\n",
    " 'min_s2': 0.0,\n",
    " 'min_s3': 0.0,\n",
    " 'min_total': 0.0}\n",
    "```\n",
    "De esta manera podemos comparar los valores sobre `df1` y `df_protected_final`\n",
    "```python\n",
    "stats = pd.DataFrame([compute_statistics(df1), compute_statistics(df_protected_final)])\n",
    "\n",
    "```\n",
    "En `stats` tenemos un `DataFrame` donde podemos ver los resultados.\n",
    "`\n",
    "En este ejercicio se pide:\n",
    "- implementar la función `compute_statistics` tal como se pide,\n",
    "- mostrar el resultado en el `DataFrame` stats como se indica anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe con stats    avg_subject0  max_subject0  min_subject0  avg_subject1  max_subject1  \\\n",
      "0      5.417870     10.000000      0.000000      5.462770     10.000000   \n",
      "1      5.219324     57.964143    -54.317962      5.560443     59.141741   \n",
      "\n",
      "   min_subject1  avg_subject2  max_subject2  min_subject2  avg_subject3  \\\n",
      "0      0.000000      5.408580     10.000000      0.000000      5.327550   \n",
      "1    -53.602085      5.496744     66.411919    -48.325699      5.291929   \n",
      "\n",
      "   max_subject3  min_subject3  avg_total  max_total  min_total  \n",
      "0     10.000000      0.000000   5.404193  10.000000   0.000000  \n",
      "1     60.296152    -53.760474   5.392110  66.411919 -53.760474  \n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def compute_statistics(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    ## Code goes here\n",
    "    result = dict()\n",
    "    n = 0\n",
    "    sum = 0.0\n",
    "    min_v = 0\n",
    "    max_v = 0\n",
    "    for name, values in df.items():\n",
    "        value = values.mean()\n",
    "        result[f\"avg_{name}\"] = value\n",
    "        result[f\"max_{name}\"] = values.max()\n",
    "        result[f\"min_{name}\"] = values.min()\n",
    "        if n > 0:\n",
    "            min_v = min(min_v, values.min())\n",
    "            max_v = max(max_v, values.max())\n",
    "        n = n + 1\n",
    "        sum = sum + value\n",
    "\n",
    "    result[f\"avg_total\"] = sum / n\n",
    "    result[f\"max_total\"] = max_v\n",
    "    result[f\"min_total\"] = min_v\n",
    "    #print (result)\n",
    "    return result\n",
    "\n",
    "## Code goes here\n",
    "df_protected_final = noise_add_normal(df1, p_found)\n",
    "\n",
    "stats = pd.DataFrame([compute_statistics(df1), compute_statistics(df_protected_final)])\n",
    "print (f\"dataframe con stats {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacidad diferencial\n",
    "\n",
    "Ahora vamos a ver el enfoque que propone la privacidad diferencial, y para ello implementaremos de forma simulada una base de datos como una clase de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La siguiente clase implementa una sencilla base de datos `MyDB`. La base de datos lee el fichero CSV que contiene los datos con las notas de los estudiantes.\n",
    "\n",
    "Como vemos, se trata de una base de datos muy sencilla y simplificada, que únicamente tiene sentido con fines docentes. La idea es que la clase `MyDB` simula una base de datos y sus métodos públicos son las consultas que pueden hacer los usuarios. Asumimos que un usuario no puede ver el contenido del objeto y simplemente puede acceder a `MyDB` mediante sus métodos.\n",
    "\n",
    "La clase `MyDB` se instancia a partir de un fichero CSV que se guarda como un `DataFrame` de `pandas`. Esta clase implementa 1 método para obtener información sobre las estudiantes de la base de datos:\n",
    "- `count_all_fail`: que retorna el número de estudiantes que han suspendido todas las asignaturas.\n",
    "\n",
    "Recordamos que asumimos que la única manera que tiene cualquier usuario para acceder a los datos es llamar a esta función `count_all_fail`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDB:\n",
    "    def __init__(self, filename: str) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "\n",
    "    def count_all_fail(self) -> int:\n",
    "        return self.df[\n",
    "            (self.df[\"subject0\"] < 5)\n",
    "            & (self.df[\"subject1\"] < 5)\n",
    "            & (self.df[\"subject2\"] < 5)\n",
    "            & (self.df[\"subject3\"] < 5)\n",
    "            ].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, a continuación vemos como se instanciaría `SimpleDB` con el fichero `data/students1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB1 count_all_fail: 420\n"
     ]
    }
   ],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "\n",
    "print(f\"DB1 count_all_fail: {db1.count_all_fail()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "*[0.5p]*\n",
    "\n",
    "Vamos ahora a estudiar la privacidad que ofrece `MyDB` según la definición de privacidad diferencial. Con el objeto de poder hacer diversas pruebas tenemos dos ficheros CSV:\n",
    "- `data/students1.csv`: con 10000 registros\n",
    "- `data/students2.csv`: con 9999 registros\n",
    "\n",
    "Podemos ver que `students2.csv` es igual a `students1.csv` con la diferencia de que le falta un registro, el correspondiente a *Susan Duffy*. En principio podemos asumir que un posible atacante sabe que este es el registro que falta (el correspondiente a esta estudiante no está en DB2 y sí en DB1), pero no sabe sus datos: notas obtenidas en las asignaturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = MyDB(\"data/students1.csv\")\n",
    "db2 = MyDB(\"data/students2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observando el resultado de hacer la consulta `count_all_fail` a `db1` y `db2`. ¿Qué información podemos obtener? (Muestra el resultado de las consultas y añade la respuesta y su justificación como comentario).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de suspendidos con Susan 420 y sin Susan 420\n",
      "Susan no ha suspendido la asignatura\n"
     ]
    }
   ],
   "source": [
    "## Code goes here\n",
    "print (f\"número de suspendidos con Susan {db1.count_all_fail()} y sin Susan {db2.count_all_fail()}\")\n",
    "\n",
    "# Si el número de suspendidos de las dos muestras es igual es que el estudiante eliminado no suspendió\n",
    "if db1.count_all_fail() == db2.count_all_fail():\n",
    "    print (\"Susan no ha suspendido la asignatura\")\n",
    "else:\n",
    "    print (\"Susan ha suspendido la asignatura\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "*[1.25p]*\n",
    "\n",
    "Vamos a implementar una nueva base de datos que implemente la versión segura del método `count_all_fail` utilizando el mecanismo de Laplace. Para ello crearemos una nueva clase de base de datos a la que llamaremos `MyPrivateDB`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementa, en la siguiente clase, el método `dp_count_all_fail` que retorne el número de alumnos y alumnas que han suspendido todas las asignaturas, pero esta vez la respuesta ha de estar protegida utilizando **el mecanismo de Laplace**.\n",
    "\n",
    "Para hacerlo necesitaremos:\n",
    "- Calcular o determinar la sensibilidad global del método.\n",
    "- Generar ruido con una distribución de Laplace basándonos en su sensibilidad global y el parámetro *epsilon*.\n",
    "- Retornar el valor con el ruido añadido.\n",
    "\n",
    "Como vemos, el parámetro *epsilon* se fija en el constructor de la clase. Importante: de momento asumimos que únicamente se realizará una consulta.\n",
    "\n",
    "*Hint*: \n",
    "- [random.Generator.laplace](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.laplace.html#numpy.random.Generator.laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyPrivateDB:\n",
    "    def __init__(self, filename: str, epsilon: float) -> None:\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.epsilon = epsilon\n",
    "        self.rng = np.random.default_rng()\n",
    "        # en este caso la sensibilidad global es 1, porque la diferencia máxima entre el número de estudiantes suspendidos \n",
    "        # entre la muestra con y sin un estudiante, sólo puede ser de 1, dado que o suspende o no.\n",
    "        self.global_sensitivity = 1\n",
    "\n",
    "    def dp_count_all_fail(self) -> int:\n",
    "        ## Code goes here\n",
    "        original_value = self.df[\n",
    "            (self.df[\"subject0\"] < 5)\n",
    "            & (self.df[\"subject1\"] < 5)\n",
    "            & (self.df[\"subject2\"] < 5)\n",
    "            & (self.df[\"subject3\"] < 5)\n",
    "            ].shape[0]\n",
    "\n",
    "        # aplicamos ruido al número de alumnos suspendidos, mediante la distribución de Laplace centrada en 0 y escala\n",
    "        # calculada a partir de la sensibilidad global y el epsilon. \n",
    "        lap = self.rng.laplace(0, self.global_sensitivity / self.epsilon, 1)\n",
    "        return int(original_value + lap[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "*[0.5p]*\n",
    "\n",
    "Podemos ver el resultado de hacer la consulta `dp_count_all_fail` con la nueva base de datos `MyPrivateDB` a los datos de `data/students1.csv` y `data/students2.csv`.\n",
    "\n",
    "¿Podemos ahora obtener la misma información que en el Ejercicio 6? Muestra el resultado para `epsilon=1`, responde y justifica en forma de comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de suspendidos con Susan 418 y sin Susan 419\n"
     ]
    }
   ],
   "source": [
    "## Code goes here\n",
    "\n",
    "db1_private = MyPrivateDB(\"data/students1.csv\", epsilon=1)\n",
    "db2_private = MyPrivateDB(\"data/students2.csv\", epsilon=1)\n",
    "\n",
    "print (f\"número de suspendidos con Susan {db1_private.dp_count_all_fail()} y sin Susan {db2_private.dp_count_all_fail()}\")\n",
    "# dado que el número de suspendidos entre las dos muestras, está \"manipulado\", con un primer resultado no podemos determinar a ciencia cierta si \n",
    "# Susan está o no suspendida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "*[2p]*\n",
    "\n",
    "Hemos asumido al principio que el usuario o usuaria únicamente realizará una consulta (llamará a la función `dp_count_all_fail()` una vez).\n",
    "\n",
    "Si ahora asumimos que se puede hacer más de una consulta, y sin modificar la implementación de nuestro método `dp_count_all_fail`, un atacante ¿podría llegar a obtener la misma información que proporcionaba el método `count_all_fail` pero utilizando `dp_count_all_fail`?\n",
    "\n",
    "En este ejercicio se pide implementar el posible ataque que permita desanonimizar `dp_count_all_fail` (es decir, utilizando `MyPrivateDB`) y con la particularidad de que se puede repetir dicha consulta sobre una misma base de datos diversas veces. En este caso lo haremos para `epsilon=8`. Justifica el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "después de 80 tests hay un total de 43 muestras en que no hay mas suspendidos entre ayer y hoy. Eso quiere decir que hay una probabilidad del 53.75% de que Susana no haya suspendido\n"
     ]
    }
   ],
   "source": [
    "## Code goes here\n",
    "## supondremos que students2.csv contiene los datos de ayer y \n",
    "## students1.csv los datos de hoy, y es donde se incorporan los datos de Susana de la que queremos descubrir si ha suspendido o no\n",
    "\n",
    "# contiene los datos de ayer\n",
    "db2_private8 = MyPrivateDB(\"data/students2.csv\", epsilon=8)\n",
    "\n",
    "\n",
    "# contiene los datos de hoy\n",
    "db1_private8 = MyPrivateDB(\"data/students1.csv\", epsilon=8)\n",
    "\n",
    "# tenenmos el resultado de la consulta de ayer\n",
    "suspendidos_ayer = db2_private8.dp_count_all_fail()\n",
    "\n",
    "# como la consulta resultante, está modificada, realizaremos varios intentos, para ver como se comporta la diferencia\n",
    "n = 0\n",
    "s = 0\n",
    "for i in range(80):\n",
    "    # realizamos la consulta \"hoy\"\n",
    "    suspendidos_hoy = db1_private8.dp_count_all_fail()\n",
    "    if suspendidos_hoy <= suspendidos_ayer:\n",
    "        s = s + 1\n",
    "    n = n + 1\n",
    "\n",
    "print (f\"después de {n} tests hay un total de {s} muestras en que no hay mas suspendidos entre ayer y hoy. Eso quiere decir que hay una probabilidad del {100.0*s/n}% de que Susana no haya suspendido\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "name": "pra1-notebook.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
